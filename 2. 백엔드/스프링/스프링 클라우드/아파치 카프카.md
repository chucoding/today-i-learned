# Apache Kafka
Apache Software Foundation의 Scalar 언어로 된 오픈 소스 메시지 브로커 프로젝트
- 링크드인에서 개발 => Confluent
- Apple, Netflix, Kakao 등등 많은 회사에서 사용중.
- 대용량, 안정성 측면에서 RabbitMQ 보다 우위.
- 실시간 전송가능 및 확장성이 높음(DB 종류에 상관없이 카프카로 부터 받아오면 됨.)
- Scale-out 가능

## Kafka Broker
Kafka Application Server

- 3대 이상의 Broker Cluster 구성 권장
- Zookeeper (메타데이터 저장 및 Controller 정보 저장 ex. Broker ID, Controller ID)
- Broker n개 중 1대는 Controller 기능 수행
    - 각 Broker 파티션 할당
    - Broker 모니터링

## Kafka 설치
https://kafka.apache.org/downloads

```cmd
tar -xvf 다운로드파일
```

## Kafka 기동
### Zookeeper
기본 포트 번호 : 2181
```sh
$KAFKA_HOME/bin/zookeeper-server-start.sh $KAFKA_HOME/config/zookeeper.properties
```
```cmd
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties
```

💡 window에서 기동시 주의사항
> 입력 줄이 너무 깁니다.
명령 구문이 올바르지 않습니다.

kafka-server-start.bat실행시 같은 폴더 안에 있는 kafka-run-class.bat를 참조하여 같이 실행시키는데 여기서 너무 많은 classpath를 호출하여 문제가 생길 수 있다. (윈도우 cmd는 명령줄에 8192글자까지 제한)

따라서 kafka-run-class.bat을 다음과 같이 수정(대략 93라인쯤 위치)

before
```cmd
rem Classpath addition for release
for %%i in ("%BASE_DIR%\libs\*") do (
call :concat "%%i"
)
```

after
```cmd
rem Classpath addition for release
call :concat "%BASE_DIR%\libs\*;
```

### Kafka Server
기본 포트 번호 : 9092
```sh
$KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/server.properties
```
```cmd
.\bin\windows\kafka-server-start.bat .\config\server.properties
```

## Kafka Core (Client)
카프카에 메시지를 보내면 컨슈머(java 프로그램)로 전달해주는 클라이언트 프로그램

### Topic
카프카에서 메시지가 저장되는 곳

Topic 생성
```bash
$KAFKA_HOME/bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092 --partitions 1
```
```cmd
.\kafka-topics.bat --create --topic quickstart-e
vents --bootstrap-server localhost:9092 --partitions 1
```
- quickstart-events : 토픽이름
- localhost:9092 : 카프카 기본서버
- partitions : 멀티 클러스터링 설정
  
Topic 목록 확인
```bash
$KAFKA_HOME/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list
```
```cmd
.\kafka-topics.bat --bootstrap-server localhost:9092 --list
```

Topic 정보 확인
```bash
$KAFKA_HOME/bin/kafka-topics.sh --describe --topic quickstart-events --bootstrap-server localhost:9092
```
```cmd
.\kafka-topics.bat --describe --topic quickstart-events --bootstrap-server localhost:9092
```

### Producer
메시지 생산

```bash
$KAFKA_HOME/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic quickstart-events
```
```cmd
.\kafka-console-producer.bat --broker-list local
host:9092 --topic quickstart-events
```

### Consumer
메시지 소비

```bash
$KAFKA_HOME/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic quickstart-events --from-beginning
```
```cmd
.\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic quickstart-events --from-beginning
```
- --from-beginning : 처음부터 받아가는 옵션

## Kafka Connect
Data를 Import/Export 가능 (Kafka Connect Source/Kafka Connect Sink)

- 코드 없이 Configuration으로 데이터를 이동
- Standalone mode, Distribution mode 지원
    - RESTful API 사용 가능 (커넥터 생성, 삭제 등)
    - Stream 또는 Batch 형태로 데이터 전송 가능
    - 커스텀 Connector를 통한 다양한 Plugin 제공 (File, S3, Hive, Mysql, etc ...)

### Kafka Connect 설치
```cmd
curl -O http://packages.confluent.io/archive/6.1/confluent-community-6.1.0.tar.gz
```

### Kafka Connect 실행
❗ zookiper와 kafka-server가 먼저 기동되어 있어야 실행된다.

```cmd
.\bin\Windows\connect-distributed.bat .\etc\kafka\connect-distributed.properties
```
❗ Classpath is empty. Please build the project first e.g. by running 'gradlew jarAll' 오류
>.\bin\windows\kafka-run-class.bat 파일에서 rem Classpath addition for core 부분을 찾아서, 그 위에 다음 코드 삽입
```bat
rem classpath addition for LSB style path
if exist %BASE_DIR%\share\java\kafka\* (
    call:concat %BASE_DIR%\share\java\kafka\*
)
```

### Topic 목록 확인
Kafka Connect 실행하고 나면 다음과 같이 3개의 토픽이 생성되어 있는것을 확인할 수 있음.
```
connect-configs
connect-offsets
connect-status
```

### JDBC Connector 설치
1. JdbcSourceConnector zip 파일 다운로드
https://www.confluent.io/hub/confluentinc/kafka-connect-jdbc

2. etc/kafka/connect-distributed.properties 파일 마지막에 아래 plugin 정보 추가
```properties
plugin.path=\C:\\Users\\hssuh\\DISK\\spring-cloud\\kafka\\confluentinc-kafka-connect-jdbc-10.0.2\\lib
```

3. JdbcSourceConnector에서 MariaDB 사용하기 위해 mariadb 드라이버 복사
- ${USER.HOME}\.m2 폴더에서 mariadb-java-client-2.7.1.jar 파일을 ./share/java/kafka/ 하위에 복사


### Kafka Connect Source
카프카로 데이터 전달해주는 역할

MariaDB 정보를 Kafka Source Connect에 등록해놓으면 추후에 DB에서 변경사항이 생기면 토픽에 저장되는 형태
```curl
echo '
{
    "name" : "my-source-connect",
    "config" : {
        "connector.class" : "io.confluent.connect.jdbc.JdbcSourceConnector",
        "connection.url":"jdbc:mysql://localhost:3306/mydb",
        "connection.user":"root",
        "connection.password":"test1357",
        "mode":"incrementing", // 자동으로 증가시켜주는 옵션
        "incrementing.column.name":"id",
        "table.whitelist":"users",  // users table 변경사항 감지
        "topic.prefix":"my_topic_", // 토픽 이름 prefix 등록
        "tasks.max":"1"
    }
}
' | curl -X POST -d @- http://localhost:8083/connectors --header "content-Type:application/json"
```

### Kafka Connect Sink
카프카의 데이터를 데이터베이스로 전달해주는 역할

아래와 같은 포멧으로 topic에 전달
```
{
    "schema":{
        "type":"struct",
        "fields":[
            {"type":"int32","optional":false,"field":"id"},
            {"type":"string","optional":true,"field":"user_id"},{"type":"string","optional":true,"field":"pwd"},{"type":"string","optional":true,"field":"name"},{"type":"int64","optional":true,"name":"org.apache.kafka.connect.data.Timestamp","version":1,"field":"created_at"}
        ],
        "optional":false,
        "name":"users"
    },
    "payload":{
        "id":1,
        "user_id":"users",
        "pwd":"test1111",
        "name":"User name",
        "created_at":1708644247000
    }
}
```